
data:
  dataset_name: 'LBBDMxVq13'
  dataset_type: 'custom_aligned'
  dataset_config:
    max_pixel_ori: 32767 # Pet 
    max_pixel_cond: 2047  # CT
    dataset_path: '/workdir/carrot/splited_data_120k'
    image_size: 256
    channels: 1
    to_normal: True 
    flip: False
  train:
    batch_size: 64
    shuffle: True
  val:
    batch_size: 64
    shuffle: True
  test:
    batch_size: 64
    # shuffle: False
model: 
  BB: 
    lr_scheduler:
      cooldown: 3000
      factor: 0.5
      min_lr: 5.0e-07
      patience: 3000
      threshold: 0.0001
    optimizer: 
      beta1: 0.9
      lr: 0.0001
      optimizer: Adam
      weight_decay: 0.0
    params: 
      UNetParams:
        attention_resolutions: !!python/tuple
        - 32
        - 16
        - 8
        channel_mult: !!python/tuple
        - 1
        - 2
        - 3
        - 4
        condition_key: nocond
        context_dim:
        conv_resample: True
        dims: 2
        image_size: 64
        in_channels: 3
        model_channels: 128
        num_head_channels: 64
        num_heads: 8
        num_res_blocks: 2
        out_channels: 3
        resblock_updown: True
        use_scale_shift_norm: True
        use_spatial_transformer: False
      eta: 1.0
      loss_type: l1
      max_var: 1.0
      mt_type: linear
      num_timesteps: 1000
      objective: grad
      sample_step: 200
      sample_type: linear
      skip_sample: True
  CondStageParams: 
    in_channels: 3
    n_stages: 2
    out_channels: 3
  EMA: 
    ema_decay: 0.995
    start_ema_step: 30000
    update_ema_interval: 8
    use_ema: True
  VQGAN: 
    params:
      ckpt_path: /workdir/carrot/vqgan/vq1_3_69.ckpt
      ddconfig: 
        attn_resolutions: []
        ch: 128
        ch_mult: !!python/tuple
        - 1
        - 2
        - 4
        double_z: False
        dropout: 0.0
        in_channels: 1
        out_ch: 1
        num_res_blocks: 1
        
        resolution: 256
        z_channels: 3
      embed_dim: 3
      lossconfig: 
        target: torch.nn.Identity
      n_embed: 8192
  latent_before_quant_conv: False
  # model_load_path: ./results/108_CT2PET/LBBDM-f4/checkpoint/last_model.pth
  model_name: LBBDM-f4
  model_type: LBBDM
  normalize_latent: False
  only_load_latent_mean_std: False
  # optim_sche_load_path: ./results/108_CT2PET/LBBDM-f4/checkpoint/last_optim_sche.pth

runner: BBDMRunner
testing: 
  clip_denoised: False 
  sample_num: 1
training: 
  accumulate_grad_batches: 4
  n_epochs: 200
  n_steps: 200000
  sample_interval: 2
  save_interval: 2
  validation_interval: 2